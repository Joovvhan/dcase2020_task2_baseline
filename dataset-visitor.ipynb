{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import random\n",
    "\n",
    "from collections import namedtuple\n",
    "\n",
    "import librosa\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import IPython.display as ipd\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import queue\n",
    "\n",
    "import time\n",
    "\n",
    "import threading\n",
    "\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.nn import Parameter # arcface-pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FileInfo = namedtuple('file_info', 'file_path mode equipment status equip_id file_id')\n",
    "\n",
    "BatchData = namedtuple('batch_data', 'mel equipment status')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path = 'dev_data/*'\n",
    "\n",
    "dataset_direc_list = [path for path in glob.glob(dataset_path) if os.path.isdir(path)]\n",
    "dataset_direc_list.sort()\n",
    "\n",
    "print(dataset_direc_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "equipments = ['ToyCar', 'ToyConveyor', 'fan', 'pump', 'slider', 'valve']\n",
    "\n",
    "num_equipments = len(equipments)\n",
    "\n",
    "EQUIPMENT_DICT = {\n",
    "    equip: i for i, equip in enumerate(equipments)\n",
    "}\n",
    "\n",
    "status = ['normal', 'anomaly']\n",
    "\n",
    "STATUS_DICT = {\n",
    "    stat: i for i, stat in enumerate(status)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "STATUS_DICT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_metadata(dataset_dir, mode='train'):\n",
    "    \n",
    "    file_path_list = glob.glob(direc + '/' + mode + '/*.wav')\n",
    "    file_path_list.sort()\n",
    "    metadata = [FileInfo(file_path, mode, os.path.basename(direc), *path_to_file_info(file_path)) for file_path in file_path_list]\n",
    "\n",
    "    return metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def path_to_file_info(path):\n",
    "    \n",
    "    '''\n",
    "    return status, equip_id, file_num\n",
    "    '''\n",
    "    \n",
    "    segments = os.path.basename(path).split('_')\n",
    "    \n",
    "    return segments[0], segments[2], segments[3]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def audio_visual_inspection(metadatum):\n",
    "    file = getattr(metadatum, 'file_path')\n",
    "\n",
    "    print(file)\n",
    "\n",
    "    y, sr = librosa.core.load(file, sr=None)\n",
    "    \n",
    "    mel = librosa.feature.melspectrogram(y, sr=sr, n_fft=int(sr * 0.1), hop_length=int(sr * 0.05), power=1, n_mels=160)\n",
    "    mel = 20 * np.log10(np.maximum(mel, 1e-8))\n",
    "\n",
    "    fig, axes = plt.subplots(2, 1, figsize=(15, 6))\n",
    "    axes[0].plot(y)\n",
    "    axes[0].set_xlim([0, len(y)])\n",
    "    axes[1].imshow(mel, origin='reversed', aspect='auto')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    print(mel.shape)\n",
    "\n",
    "    return ipd.Audio(y, rate=sr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "metadata_train = list()\n",
    "metadata_test = list()\n",
    "\n",
    "for direc in dataset_direc_list:\n",
    "# direc = random.choice(dataset_direc_list)\n",
    "\n",
    "# print(direc)\n",
    "\n",
    "#     metadata_train.append(get_metadata(direc, 'train'))\n",
    "#     metadata_test.append(get_metadata(direc, 'test'))\n",
    "    metadata_train += get_metadata(direc, 'train')\n",
    "    metadata_test += get_metadata(direc, 'test')\n",
    "    \n",
    "# print(list(map(len, metadata_train)))\n",
    "# print(list(map(len, metadata_test)))\n",
    "\n",
    "print(len(metadata_train))\n",
    "print(len(metadata_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_mel(file_path):\n",
    "\n",
    "    y, sr = librosa.core.load(file_path, sr=None)\n",
    "    \n",
    "    y = y[:sr * 10]\n",
    "    \n",
    "    mel = librosa.feature.melspectrogram(y, sr=sr, n_fft=int(sr * 0.1), hop_length=int(sr * 0.05), power=1, n_mels=160)\n",
    "    mel = (20 * np.log10(np.maximum(mel, 1e-8)) + 160 ) / 160\n",
    "    \n",
    "    return mel\n",
    "\n",
    "def batch_list_to_batch(batch_list):\n",
    "    \n",
    "    mel_batch_list = list()\n",
    "    equip_list = list()\n",
    "    status_list = list()\n",
    "    \n",
    "    for mel, equip, status in batch_list:\n",
    "        mel_batch_list.append(mel)\n",
    "        equip_list.append(EQUIPMENT_DICT[equip])\n",
    "        status_list.append(STATUS_DICT[status])\n",
    "        \n",
    "    # print(mel.shape) # (16, 160, 201)\n",
    "    \n",
    "    return BatchData(np.stack(mel_batch_list), np.array(equip_list, dtype=int), np.array(status_list, dtype=int))\n",
    "\n",
    "class DatasetFeeder:\n",
    "    \n",
    "    def __init__(self, metadata_list):\n",
    "        self.batch_queue = queue.Queue(maxsize=100)\n",
    "        self.batch_size = BATCH_SIZE\n",
    "        self.metadata_list = metadata_list\n",
    "        self.batching_finished = False\n",
    "        self.max_batch_num = int(np.ceil(len(self.metadata_list) / self.batch_size))\n",
    "        \n",
    "    def start_batching(self):\n",
    "        \n",
    "        random.shuffle(self.metadata_list)\n",
    "        \n",
    "        batch_data_list = list()\n",
    "        \n",
    "        for metadata in self.metadata_list:\n",
    "            \n",
    "            file_path = getattr(metadata, 'file_path')\n",
    "            equipment = getattr(metadata, 'equipment')\n",
    "            status = getattr(metadata, 'status')\n",
    "            \n",
    "            mel = load_mel(file_path)\n",
    "            \n",
    "            batch_data_list.append((mel, equipment, status))\n",
    "            \n",
    "            if len(batch_data_list) >= self.batch_size:\n",
    "                self.batch_queue.put(batch_list_to_batch(batch_data_list))\n",
    "                batch_data_list = list()\n",
    "        \n",
    "        if len(batch_data_list) > 0:\n",
    "            self.batch_queue.put(batch_list_to_batch(batch_data_list))\n",
    "            batch_data_list = list()\n",
    "            \n",
    "        self.batching_finished = True\n",
    "    \n",
    "    def batch_generator(self):\n",
    "        \n",
    "        self.batching_finished = False\n",
    "        t = threading.Thread(target=self.start_batching, args=())\n",
    "        t.start()\n",
    "        \n",
    "        while not (self.batching_finished and self.batch_queue.empty()):\n",
    "            try : \n",
    "                batch = self.batch_queue.get_nowait()\n",
    "                yield batch\n",
    "                \n",
    "            except:\n",
    "                time.sleep(1)\n",
    "                \n",
    "        t.join()\n",
    "            \n",
    "        return 0\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CRNN_Model(nn.Module):\n",
    "    \n",
    "    def __init__(self, device, s=5, m=0.35):\n",
    "        super(CRNN_Model, self).__init__()\n",
    "        self.cnn_layers_1 = nn.Sequential(nn.Conv2d(1, 64, (9, 3), dilation=2), \n",
    "                                        nn.BatchNorm2d(64), \n",
    "                                        nn.ReLU(),\n",
    "                                        nn.Conv2d(64, 128, (9, 3), dilation=2), \n",
    "                                        nn.BatchNorm2d(128),\n",
    "                                        nn.ReLU())\n",
    "        \n",
    "        self.cnn_layers_2 = nn.Sequential(nn.Conv2d(128, 128, (9, 3), dilation=2), \n",
    "                                nn.BatchNorm2d(128), \n",
    "                                nn.ReLU(),\n",
    "                                nn.Conv2d(128, 128, (9, 3), dilation=2), \n",
    "                                nn.BatchNorm2d(128),\n",
    "                                nn.ReLU())\n",
    "        \n",
    "        self.cnn_layers_3 = nn.Sequential(nn.Conv2d(128, 256, (9, 3), dilation=2), \n",
    "                        nn.BatchNorm2d(256), \n",
    "                        nn.ReLU(),\n",
    "                        nn.Conv2d(256, 256, (9, 3), dilation=2), \n",
    "                        nn.BatchNorm2d(256),\n",
    "                        nn.ReLU())\n",
    "        \n",
    "        self.cnn_layers_4 = nn.Sequential(nn.Conv2d(256, 256, (9, 3), dilation=2), \n",
    "                nn.BatchNorm2d(256), \n",
    "                nn.ReLU(),\n",
    "                nn.Conv2d(256, 256, (9, 3), dilation=2), \n",
    "                nn.BatchNorm2d(256),\n",
    "                nn.ReLU())\n",
    "        \n",
    "        self.cnn_layers_5 = nn.Sequential(nn.Conv2d(256, 512, (32, 3)), \n",
    "        nn.BatchNorm2d(512), \n",
    "        nn.ReLU()) # (B, H, 1, L)\n",
    "\n",
    "        self.rnn_layers = nn.ModuleList((nn.GRU(512, 256, batch_first=True),\n",
    "                                        nn.GRU(256, 256, batch_first=True),\n",
    "                                        nn.GRU(256, 256, batch_first=True)))\n",
    "        \n",
    "        # GRU (B, L, H)\n",
    "        # nn.utils.weight_norm(nn.linear(256, 6, bias=True), name='weight')\n",
    "#         self.W = nn.Linear(256, 6, bias=True)\n",
    "#         self.W = nn.utils.weight_norm(nn.Linear(256, 6, bias=True), name='weight')\n",
    "    \n",
    "        self.W = Parameter(torch.FloatTensor(6, 256), requires_grad=True)\n",
    "        nn.init.xavier_uniform_(self.W)\n",
    "        \n",
    "        self.s = s\n",
    "        self.m = m\n",
    "        \n",
    "        self.cos_m = np.cos(m)\n",
    "        self.sin_m = np.sin(m)\n",
    "        \n",
    "        self.device = device\n",
    "        \n",
    "    def forward(self, input_tensor, label_tensor):\n",
    "        \n",
    "        # print(input_tensor.shape)\n",
    "        tensor = self.cnn_layers_1(input_tensor); # print(tensor.shape)\n",
    "        tensor = self.cnn_layers_2(tensor); # print(tensor.shape)\n",
    "        tensor = self.cnn_layers_3(tensor); # print(tensor.shape)        \n",
    "        tensor = self.cnn_layers_4(tensor); # print(tensor.shape)\n",
    "        tensor = self.cnn_layers_5(tensor); # print(tensor.shape)\n",
    "        tensor = torch.squeeze(tensor, 2) # (B, H, 1, L) => (B, H, L)\n",
    "        tensor.transpose_(1, 2); # print(tensor.shape) # (B, H, L) => (B, L, H)\n",
    "        \n",
    "        for rnn_layer in self.rnn_layers:\n",
    "            tensor, _ = rnn_layer(tensor) # (B, L, H)\n",
    "        \n",
    "        # print(tensor.shape)\n",
    "        \n",
    "#         tensor = self.W(tensor) # (B, L, H) => (B, L, C)\n",
    "        \n",
    "        cosine_tensor = F.linear(F.normalize(tensor), F.normalize(self.W)) # (B, L, C)\n",
    "        sine_tensor = torch.sqrt((1.0 - torch.pow(cosine_tensor, 2))) # (B, L, C)\n",
    "        phi_tensor = cosine_tensor * self.cos_m - sine_tensor * self.sin_m # (B, L, C)\n",
    "                             \n",
    "        one_hot = torch.zeros([label_tensor.shape[0], 6]).to(self.device)\n",
    "        one_hot.scatter_(1, label_tensor, 1)\n",
    "        one_hot.unsqueeze_(1)\n",
    "        one_hot.repeat((1, phi_tensor.shape[1], 1)).shape # (B, L, C)\n",
    "        \n",
    "        output_tensor = (one_hot * phi_tensor) + ((1.0 - one_hot) * cosine_tensor)\n",
    "        output_tensor *= self.s\n",
    "        \n",
    "        return output_tensor, cosine_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = CRNN_Model(device).to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.0001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for param in net.parameters():\n",
    "#     print(param.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset_feeder = DatasetFeeder(metadata_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# one_hot = torch.zeros([16, 6])\n",
    "# print(one_hot.shape)\n",
    "\n",
    "# label = torch.tensor(batch[1]).view(len(label),1)\n",
    "# print(label.shape)\n",
    "\n",
    "# one_hot.scatter_(1, label, 1)\n",
    "\n",
    "# one_hot.unsqueeze_(1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix = np.array([i for i in range(16 * 4 * 6)]).reshape([16, 4, 6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix[0, 0, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_tensor = torch.tensor(matrix)\n",
    "\n",
    "print(m_tensor[0, 0, :])\n",
    "\n",
    "print(m_tensor[0, 1, :])\n",
    "\n",
    "print(m_tensor[0, 2, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# m_tensor.transpose_(0, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_m_tensor = m_tensor.reshape(-1, m_tensor.shape[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(new_m_tensor[0, :])\n",
    "\n",
    "print(new_m_tensor[1, :])\n",
    "\n",
    "print(new_m_tensor[2, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [ B, L, C ] => # [ B x L, C ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "loss_history = list()\n",
    "\n",
    "for i, batch in tqdm(enumerate(train_dataset_feeder.batch_generator()), total=train_dataset_feeder.max_batch_num):\n",
    "    \n",
    "    mel_batch = torch.tensor(np.expand_dims(batch[0], 1)).to(device)\n",
    "    \n",
    "    label = torch.tensor(batch[1]).view(len(batch[1]), 1).to(device)\n",
    "        \n",
    "    output_tensor, cosine_tensor = net(mel_batch, label)\n",
    "    \n",
    "    expanded_label = label.repeat(1, output_tensor.shape[1])\n",
    "    \n",
    "    expanded_label = expanded_label.reshape(-1) # B x L\n",
    "    \n",
    "    output_tensor = output_tensor.reshape(-1, output_tensor.shape[-1]) # (B x L, C)\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    loss = criterion(output_tensor, expanded_label)\n",
    "    \n",
    "    loss.backward()\n",
    "    \n",
    "    optimizer.step()\n",
    "    \n",
    "    loss_history.append(loss.item())\n",
    "    \n",
    "#     print(\"#############\")\n",
    "#     print(label.T)  \n",
    "#     print(loss.item())\n",
    "#     print(output_tensor.shape)\n",
    "#     print()\n",
    "    \n",
    "    \n",
    "    if i % 20 == 0:\n",
    "        print(len(loss_history))\n",
    "        print(loss_history)\n",
    "        plt.figure()\n",
    "        plt.plot(loss_history)\n",
    "        plt.show()\n",
    "        plt.savefig('{:03d}.png'.format(i), dpi=300)\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadatum = random.choice(metadata_train)\n",
    "audio_visual_inspection(metadatum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "while True:\n",
    "    metadatum = random.choice(metadata_test)\n",
    "    \n",
    "    if 'anom' in metadatum[0]: break\n",
    "    \n",
    "audio_visual_inspection(metadatum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "borealis",
   "language": "python",
   "name": "borealis"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
