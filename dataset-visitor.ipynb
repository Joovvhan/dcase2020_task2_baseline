{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import random\n",
    "\n",
    "from collections import namedtuple\n",
    "\n",
    "import librosa\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import IPython.display as ipd\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import queue\n",
    "\n",
    "import time\n",
    "\n",
    "import threading\n",
    "\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "FileInfo = namedtuple('file_info', 'file_path mode equipment status equip_id file_id')\n",
    "\n",
    "BatchData = namedtuple('batch_data', 'mel equipment status')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['dev_data/ToyCar', 'dev_data/ToyConveyor', 'dev_data/fan', 'dev_data/pump', 'dev_data/slider', 'dev_data/valve']\n"
     ]
    }
   ],
   "source": [
    "dataset_path = 'dev_data/*'\n",
    "\n",
    "dataset_direc_list = [path for path in glob.glob(dataset_path) if os.path.isdir(path)]\n",
    "dataset_direc_list.sort()\n",
    "\n",
    "print(dataset_direc_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "equipments = ['ToyCar', 'ToyConveyor', 'fan', 'pump', 'slider', 'valve']\n",
    "\n",
    "EQUIPMENT_DICT = {\n",
    "    equip: i for i, equip in enumerate(equipments)\n",
    "}\n",
    "\n",
    "status = ['normal', 'anomaly']\n",
    "\n",
    "STATUS_DICT = {\n",
    "    stat: i for i, stat in enumerate(status)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'normal': 0, 'anomaly': 1}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "STATUS_DICT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_metadata(dataset_dir, mode='train'):\n",
    "    \n",
    "    file_path_list = glob.glob(direc + '/' + mode + '/*.wav')\n",
    "    file_path_list.sort()\n",
    "    metadata = [FileInfo(file_path, mode, os.path.basename(direc), *path_to_file_info(file_path)) for file_path in file_path_list]\n",
    "\n",
    "    return metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def path_to_file_info(path):\n",
    "    \n",
    "    '''\n",
    "    return status, equip_id, file_num\n",
    "    '''\n",
    "    \n",
    "    segments = os.path.basename(path).split('_')\n",
    "    \n",
    "    return segments[0], segments[2], segments[3]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def audio_visual_inspection(metadatum):\n",
    "    file = getattr(metadatum, 'file_path')\n",
    "\n",
    "    print(file)\n",
    "\n",
    "    y, sr = librosa.core.load(file, sr=None)\n",
    "    \n",
    "    mel = librosa.feature.melspectrogram(y, sr=sr, n_fft=int(sr * 0.1), hop_length=int(sr * 0.05), power=1, n_mels=160)\n",
    "    mel = 20 * np.log10(np.maximum(mel, 1e-8))\n",
    "\n",
    "    fig, axes = plt.subplots(2, 1, figsize=(15, 6))\n",
    "    axes[0].plot(y)\n",
    "    axes[0].set_xlim([0, len(y)])\n",
    "    axes[1].imshow(mel, origin='reversed', aspect='auto')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    print(mel.shape)\n",
    "\n",
    "    return ipd.Audio(y, rate=sr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20119\n",
      "10868\n"
     ]
    }
   ],
   "source": [
    "metadata_train = list()\n",
    "metadata_test = list()\n",
    "\n",
    "for direc in dataset_direc_list:\n",
    "# direc = random.choice(dataset_direc_list)\n",
    "\n",
    "# print(direc)\n",
    "\n",
    "#     metadata_train.append(get_metadata(direc, 'train'))\n",
    "#     metadata_test.append(get_metadata(direc, 'test'))\n",
    "    metadata_train += get_metadata(direc, 'train')\n",
    "    metadata_test += get_metadata(direc, 'test')\n",
    "    \n",
    "# print(list(map(len, metadata_train)))\n",
    "# print(list(map(len, metadata_test)))\n",
    "\n",
    "print(len(metadata_train))\n",
    "print(len(metadata_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_mel(file_path):\n",
    "\n",
    "    y, sr = librosa.core.load(file_path, sr=None)\n",
    "    \n",
    "    y = y[:sr * 10]\n",
    "    \n",
    "    mel = librosa.feature.melspectrogram(y, sr=sr, n_fft=int(sr * 0.1), hop_length=int(sr * 0.05), power=1, n_mels=160)\n",
    "    mel = (20 * np.log10(np.maximum(mel, 1e-8)) + 160 ) / 160\n",
    "    \n",
    "    return mel\n",
    "\n",
    "def batch_list_to_batch(batch_list):\n",
    "    \n",
    "    mel_batch_list = list()\n",
    "    equip_list = list()\n",
    "    status_list = list()\n",
    "    \n",
    "    for mel, equip, status in batch_list:\n",
    "        mel_batch_list.append(mel)\n",
    "        equip_list.append(EQUIPMENT_DICT[equip])\n",
    "        status_list.append(STATUS_DICT[status])\n",
    "        \n",
    "    # print(mel.shape) # (16, 160, 201)\n",
    "    \n",
    "    return BatchData(np.stack(mel_batch_list), np.array(equip_list, dtype=int), np.array(status_list, dtype=int))\n",
    "\n",
    "class DatasetFeeder:\n",
    "    \n",
    "    def __init__(self, metadata_list):\n",
    "        self.batch_queue = queue.Queue(maxsize=100)\n",
    "        self.batch_size = 16\n",
    "        self.metadata_list = metadata_list\n",
    "        self.batching_finished = False\n",
    "        self.max_batch_num = int(np.ceil(len(self.metadata_list) / self.batch_size))\n",
    "        \n",
    "    def start_batching(self):\n",
    "        \n",
    "        random.shuffle(self.metadata_list)\n",
    "        \n",
    "        batch_data_list = list()\n",
    "        \n",
    "        for metadata in self.metadata_list:\n",
    "            \n",
    "            file_path = getattr(metadata, 'file_path')\n",
    "            equipment = getattr(metadata, 'equipment')\n",
    "            status = getattr(metadata, 'status')\n",
    "            \n",
    "            mel = load_mel(file_path)\n",
    "            \n",
    "            batch_data_list.append((mel, equipment, status))\n",
    "            \n",
    "            if len(batch_data_list) >= self.batch_size:\n",
    "                self.batch_queue.put(batch_list_to_batch(batch_data_list))\n",
    "                batch_data_list = list()\n",
    "        \n",
    "        if len(batch_data_list) > 0:\n",
    "            self.batch_queue.put(batch_list_to_batch(batch_data_list))\n",
    "            batch_data_list = list()\n",
    "            \n",
    "        self.batching_finished = True\n",
    "    \n",
    "    def batch_generator(self):\n",
    "        \n",
    "        self.batching_finished = False\n",
    "        t = threading.Thread(target=self.start_batching, args=())\n",
    "        t.start()\n",
    "        \n",
    "        while not (self.batching_finished and self.batch_queue.empty()):\n",
    "            try : \n",
    "                batch = self.batch_queue.get_nowait()\n",
    "                yield batch\n",
    "                \n",
    "                break\n",
    "                \n",
    "            except:\n",
    "                time.sleep(1)\n",
    "                \n",
    "        t.join()\n",
    "            \n",
    "        return 0\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CRNN_Model(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(CRNN_Model, self).__init__()\n",
    "        self.cnn_layers_1 = nn.Sequential(nn.Conv2d(1, 64, (9, 3), dilation=2), \n",
    "                                        nn.BatchNorm2d(64), \n",
    "                                        nn.ReLU(),\n",
    "                                        nn.Conv2d(64, 128, (9, 3), dilation=2), \n",
    "                                        nn.BatchNorm2d(128),\n",
    "                                        nn.ReLU())\n",
    "        \n",
    "        self.cnn_layers_2 = nn.Sequential(nn.Conv2d(128, 128, (9, 3), dilation=2), \n",
    "                                nn.BatchNorm2d(128), \n",
    "                                nn.ReLU(),\n",
    "                                nn.Conv2d(128, 128, (9, 3), dilation=2), \n",
    "                                nn.BatchNorm2d(128),\n",
    "                                nn.ReLU())\n",
    "        \n",
    "        self.cnn_layers_3 = nn.Sequential(nn.Conv2d(128, 256, (9, 3), dilation=2), \n",
    "                        nn.BatchNorm2d(256), \n",
    "                        nn.ReLU(),\n",
    "                        nn.Conv2d(256, 256, (9, 3), dilation=2), \n",
    "                        nn.BatchNorm2d(256),\n",
    "                        nn.ReLU())\n",
    "        \n",
    "        self.cnn_layers_4 = nn.Sequential(nn.Conv2d(256, 256, (9, 3), dilation=2), \n",
    "                nn.BatchNorm2d(256), \n",
    "                nn.ReLU(),\n",
    "                nn.Conv2d(256, 256, (9, 3), dilation=2), \n",
    "                nn.BatchNorm2d(256),\n",
    "                nn.ReLU())\n",
    "        \n",
    "        self.cnn_layers_5 = nn.Sequential(nn.Conv2d(256, 512, (32, 3)), \n",
    "        nn.BatchNorm2d(512), \n",
    "        nn.ReLU())\n",
    "\n",
    "        self.rnn_layers = nn.ModuleList((nn.GRU(512, 256, batch_first=True),\n",
    "                                        nn.GRU(256, 128, batch_first=True),\n",
    "                                        nn.GRU(128, 128, batch_first=True)))\n",
    "        \n",
    "        \n",
    "        \n",
    "    def forward(self, input_tensor):\n",
    "        \n",
    "        print(input_tensor.shape)\n",
    "        \n",
    "        tensor = self.cnn_layers_1(input_tensor)\n",
    "        \n",
    "        print(tensor.shape)\n",
    "        \n",
    "        tensor = self.cnn_layers_2(tensor)\n",
    "        \n",
    "        print(tensor.shape)\n",
    "        \n",
    "        tensor = self.cnn_layers_3(tensor)\n",
    "        \n",
    "        print(tensor.shape)\n",
    "        \n",
    "        tensor = self.cnn_layers_4(tensor)\n",
    "        \n",
    "        print(tensor.shape)\n",
    "        \n",
    "        tensor = self.cnn_layers_5(tensor)\n",
    "        \n",
    "        print(tensor.shape)\n",
    "        \n",
    "        tensor = torch.squeeze(tensor, 2)\n",
    "        \n",
    "        tensor.transpose_(1, 2)\n",
    "        \n",
    "        for rnn_layer in self.rnn_layers:\n",
    "            tensor, _ = rnn_layer(tensor)\n",
    "        \n",
    "        return tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = CRNN_Model().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "mel_batch = np.expand_dims(batch[0], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 1, 160, 201])\n",
      "torch.Size([16, 128, 128, 193])\n",
      "torch.Size([16, 128, 96, 185])\n",
      "torch.Size([16, 256, 64, 177])\n",
      "torch.Size([16, 256, 32, 169])\n",
      "torch.Size([16, 512, 1, 167])\n"
     ]
    }
   ],
   "source": [
    "output_tensor = net(torch.tensor(mel_batch).to(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([16, 167, 128])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.squeeze(output_tensor).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset_feeder = DatasetFeeder(metadata_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/1258 [00:01<21:23,  1.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(16, 160, 201)\n",
      "###############\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-72a7db72d653>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dataset_feeder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_generator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtotal\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_dataset_feeder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_batch_num\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mmel_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpand_dims\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/borealis/lib/python3.7/site-packages/tqdm/_tqdm.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    928\u001b[0m \"\"\", fp_write=getattr(self.fp, 'write', sys.stderr.write))\n\u001b[1;32m    929\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 930\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mobj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    931\u001b[0m                 \u001b[0;32myield\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    932\u001b[0m                 \u001b[0;31m# Update and possibly print the progressbar.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-13-e3d28eae89a8>\u001b[0m in \u001b[0;36mbatch_generator\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     76\u001b[0m                 \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 78\u001b[0;31m         \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     79\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/borealis/lib/python3.7/threading.py\u001b[0m in \u001b[0;36mjoin\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1042\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1043\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1044\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_wait_for_tstate_lock\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1045\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1046\u001b[0m             \u001b[0;31m# the behavior of a negative timeout isn't documented, but\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/borealis/lib/python3.7/threading.py\u001b[0m in \u001b[0;36m_wait_for_tstate_lock\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m   1058\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlock\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# already determined that the C code is done\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1059\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_stopped\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1060\u001b[0;31m         \u001b[0;32melif\u001b[0m \u001b[0mlock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mblock\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1061\u001b[0m             \u001b[0mlock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelease\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1062\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for i, batch in tqdm(enumerate(train_dataset_feeder.batch_generator()), total=train_dataset_feeder.max_batch_num):\n",
    "    \n",
    "    mel_batch = np.expand_dims(batch[0], 1)\n",
    "    \n",
    "    print(batch[0].shape)\n",
    "#     print(batch[1])\n",
    "#     print(batch[2])\n",
    "    print('###############')\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadatum = random.choice(metadata_train)\n",
    "audio_visual_inspection(metadatum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "while True:\n",
    "    metadatum = random.choice(metadata_test)\n",
    "    \n",
    "    if 'anom' in metadatum[0]: break\n",
    "    \n",
    "audio_visual_inspection(metadatum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "borealis",
   "language": "python",
   "name": "borealis"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
